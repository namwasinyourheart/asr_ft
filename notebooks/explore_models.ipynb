{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d702314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nampv1/projects/vnpost_asr\n"
     ]
    }
   ],
   "source": [
    "cd /home/nampv1/projects/vnpost_asr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517cc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list =[\n",
    "    \"/home/nampv1/models/asr/vnpost-1\",\n",
    "    \"/home/nampv1/models/asr/vnpost-2\",\n",
    "    \"/home/nampv1/models/asr/vnpost-3\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0a7b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nampv1/anaconda3/envs/asr/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utils.model_utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54d4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"configs/transcribe.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbd75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5584546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.exp_utils import setup_environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5841ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.model_utils import load_model, load_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b5324a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4fa901",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b3d2273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:\n",
      "  model_type: asr\n",
      "  pretrained_model_name_or_path: openai/whisper-small\n",
      "  pretrained_processor_name_or_path: null\n",
      "  load_in_4bit: true\n",
      "  load_in_8bit: true\n",
      "  bnb_4bit_compute_dtype: null\n",
      "  bnb_4bit_quant_type: nf4\n",
      "  bnb_4bit_use_double_quant: false\n",
      "  bnb_4bit_quant_storage: uint8\n",
      "  torch_dtype: bfloat16\n",
      "  attn_implementation: null\n",
      "  device_map: null\n",
      "  low_cpu_mem_usage: null\n",
      "  adapter_path: null\n",
      "input:\n",
      "  audio_path: data/examples/audio.wav\n",
      "generate: null\n",
      "device:\n",
      "  use_cpu: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e130788",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = cfg.model \n",
    "device_args = cfg.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68cdfae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_cpu': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d8799c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args.pretrained_model_name_or_path = \"/home/nampv1/models/asr/vnpost-2/snapshots/e37978b90ca9030d5170a5c07aadb050351a65bb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7be1a2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type: asr\n",
      "pretrained_model_name_or_path: /home/nampv1/models/asr/vnpost-2/snapshots/e37978b90ca9030d5170a5c07aadb050351a65bb\n",
      "pretrained_processor_name_or_path: null\n",
      "load_in_4bit: true\n",
      "load_in_8bit: true\n",
      "bnb_4bit_compute_dtype: null\n",
      "bnb_4bit_quant_type: nf4\n",
      "bnb_4bit_use_double_quant: false\n",
      "bnb_4bit_quant_storage: uint8\n",
      "torch_dtype: bfloat16\n",
      "attn_implementation: null\n",
      "device_map: null\n",
      "low_cpu_mem_usage: null\n",
      "adapter_path: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(model_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f01b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_args=model_args, device_args=device_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fac9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = load_processor(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e17886db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(80, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear4bit(in_features=512, out_features=512, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear4bit(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear4bit(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51865, 512, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear4bit(in_features=512, out_features=512, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperAttention(\n",
       "            (k_proj): Linear4bit(in_features=512, out_features=512, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear4bit(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear4bit(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=512, out_features=51865, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e2e7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5944a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nampv1/anaconda3/envs/asr/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adapter_path = \"/home/nampv1/models/asr/vnpost-1/\"\n",
    "base_model = model\n",
    "\n",
    "from peft import PeftModel\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "\n",
    "finetuned_model = finetuned_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b297e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(80, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear4bit(in_features=512, out_features=512, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear4bit(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear4bit(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51865, 512, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear4bit(in_features=512, out_features=512, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperAttention(\n",
       "            (k_proj): Linear4bit(in_features=512, out_features=512, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear4bit(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear4bit(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear4bit(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=512, out_features=51865, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b796a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
